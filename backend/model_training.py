import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import cv2
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import json
from pathlib import Path
import shutil
from sklearn.utils.class_weight import compute_class_weight

class PlantDiseaseModel:
    def __init__(self, input_shape=(224, 224, 3), num_classes=10):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None
        
    def build_model(self):
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Transfer Learning Ù…Ø¹ EfficientNet Ù…Ø¹ Fine-tuning
        base_model = tf.keras.applications.EfficientNetB0(
            weights='imagenet',
            include_top=False,
            input_shape=self.input_shape
        )
        
        # ØªØ¬Ù…ÙŠØ¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙÙ‚Ø·
        base_model.trainable = True
        for layer in base_model.layers[:-20]:
            layer.trainable = False
        
        self.model = keras.Sequential([
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dense(512, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.5),
            layers.Dense(256, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.2),
            layers.Dense(self.num_classes, activation='softmax')
        ])
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø¯Ù„ ØªØ¹Ù„Ù… Ù…Ù†Ø®ÙØ¶ Ù„Ù„Fine-tuning
        self.model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.0001),
            loss='categorical_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        return self.model
    
    def train(self, X_train, y_train, X_val, y_val, class_weights=None, epochs=50, batch_size=32):
        callbacks = [
            keras.callbacks.EarlyStopping(
                patience=10, 
                restore_best_weights=True,
                monitor='val_accuracy',
                mode='max',
                min_delta=0.01
            ),
            keras.callbacks.ReduceLROnPlateau(
                factor=0.5, 
                patience=5,
                monitor='val_loss',
                min_lr=1e-7,
                verbose=1
            ),
            keras.callbacks.ModelCheckpoint(
                'models/plant_disease_model.keras',
                save_best_only=True,
                monitor='val_accuracy',
                mode='max',
                verbose=1
            )
        ]
        
        history = self.model.fit(
            X_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(X_val, y_val),
            callbacks=callbacks,
            verbose=1,
            shuffle=True,
            class_weight=class_weights
        )
        
        return history

def explore_dataset(data_dir):
    """Ø§Ø³ØªÙƒØ´Ø§Ù Ù‡ÙŠÙƒÙ„ Dataset"""
    print("ðŸ” Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªÙƒØ´Ø§Ù Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    dataset_path = Path(data_dir)
    if not dataset_path.exists():
        print(f"âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ {data_dir} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
        return None
    
    classes = []
    total_images = 0
    
    for class_dir in dataset_path.iterdir():
        if class_dir.is_dir():
            class_name = class_dir.name
            # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
            image_count = 0
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
                image_count += len(list(class_dir.glob(ext)))
            
            classes.append({
                'name': class_name,
                'count': image_count,
                'path': str(class_dir)
            })
            total_images += image_count
            print(f"ðŸ“ {class_name}: {image_count} ØµÙˆØ±Ø©")
    
    print(f"ðŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙˆØ±: {total_images}")
    print(f"ðŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª: {len(classes)}")
    
    return classes

def simple_preprocess_image(image_path, target_size=(224, 224)):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ù„ØµÙˆØ± - Ø¨Ø¯ÙŠÙ„ Ø¢Ù…Ù†"""
    try:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
        image = cv2.imread(str(image_path))
        if image is None:
            return None
        
        # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ RGB
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…
        image = cv2.resize(image, target_size)
        
        # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨Ø³ÙŠØ·
        image = image.astype(np.float32) / 255.0
        
        return image
        
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¨Ø³Ø·Ø© {image_path}: {e}")
        return None

def map_to_general_diseases(original_class_name):
    """ØªØ­ÙˆÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª Ø¥Ù„Ù‰ Ø£Ù…Ø±Ø§Ø¶ Ø¹Ø§Ù…Ø© Ù„Ù„Ø£ÙˆØ±Ø§Ù‚"""
    
    disease_mapping = {
        # Ø£Ù…Ø±Ø§Ø¶ ÙØ·Ø±ÙŠØ©
        'Tomato___Early_blight': 'Ø§Ù„Ù„ÙØ­Ø©_Ø§Ù„Ù…Ø¨ÙƒØ±Ø©',
        'Potato___Early_blight': 'Ø§Ù„Ù„ÙØ­Ø©_Ø§Ù„Ù…Ø¨ÙƒØ±Ø©',
        'Tomato___Late_blight': 'Ø§Ù„Ù„ÙØ­Ø©_Ø§Ù„Ù…ØªØ£Ø®Ø±Ø©', 
        'Potato___Late_blight': 'Ø§Ù„Ù„ÙØ­Ø©_Ø§Ù„Ù…ØªØ£Ø®Ø±Ø©',
        'Tomato___Leaf_Mold': 'Ø¹ÙÙ†_Ø§Ù„Ø£ÙˆØ±Ø§Ù‚',
        'Tomato___Septoria_leaf_spot': 'Ø¨Ù‚Ø¹Ø©_Ø§Ù„Ø£ÙˆØ±Ø§Ù‚',
        
        # Ø£Ù…Ø±Ø§Ø¶ Ø¨ÙƒØªÙŠØ±ÙŠØ©
        'Tomato___Bacterial_spot': 'Ø§Ù„Ø¨Ù‚Ø¹Ø©_Ø§Ù„Ø¨ÙƒØªÙŠØ±ÙŠØ©',
        'Pepper___bell___Bacterial_spot': 'Ø§Ù„Ø¨Ù‚Ø¹Ø©_Ø§Ù„Ø¨ÙƒØªÙŠØ±ÙŠØ©',
        
        # Ø£Ù…Ø±Ø§Ø¶ ÙÙŠØ±ÙˆØ³ÙŠØ©
        'Tomato___Tomato_mosaic_virus': 'Ø§Ù„ÙÙŠØ±ÙˆØ³_Ø§Ù„ÙØ³ÙŠÙØ³Ø§Ø¦ÙŠ',
        'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 'Ø§Ù„ØªØ¬Ø¹Ø¯_Ø§Ù„Ø§ØµÙØ±',
        
        # Ø¢ÙØ§Øª Ø­Ø´Ø±ÙŠØ©
        'Tomato___Spider_mites Two-spotted_spider_mite': 'Ø§Ù„Ø¹Ù†ÙƒØ¨ÙˆØª_Ø§Ù„Ø£Ø­Ù…Ø±',
        'Tomato___Target_Spot': 'Ø§Ù„Ø¨Ù‚Ø¹Ø©_Ø§Ù„Ù‡Ø¯Ù',
        
        # Ø­Ø§Ù„Ø§Øª Ø³Ù„ÙŠÙ…Ø©
        'Tomato___healthy': 'Ø³Ù„ÙŠÙ…',
        'Pepper___bell___healthy': 'Ø³Ù„ÙŠÙ…',
        'Potato___healthy': 'Ø³Ù„ÙŠÙ…'
    }
    
    return disease_mapping.get(original_class_name, 'ØºÙŠØ±_Ù…Ø¹Ø±ÙˆÙ')

def load_plant_disease_data(data_dir, max_images_per_class=500):
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø¨Ø§ØªÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø©"""
    images = []
    labels = []
    class_names = []
    class_mapping = {}
    
    print("ðŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø¨Ø§ØªÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø©...")
    
    # Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„ÙØ¦Ø§Øª
    classes_info = explore_dataset(data_dir)
    if not classes_info:
        return None, None, None
    
    # Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© (Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù…ØªØ§Ø­Ø©)
    target_classes = [
        'Tomato___healthy', 'Tomato___Early_blight', 'Tomato___Late_blight',
        'Tomato___Bacterial_spot', 'Tomato___Target_Spot',
        'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus',
        'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot',
        'Tomato___Spider_mites Two-spotted_spider_mite',
        'Pepper___bell___healthy', 'Pepper___bell___Bacterial_spot',
        'Potato___healthy', 'Potato___Early_blight', 'Potato___Late_blight'
    ]
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªØ¹ÙŠÙŠÙ† Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    for class_info in classes_info:
        original_name = class_info['name']
        
        if original_name not in target_classes:
            continue
            
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ù…Ø±Ø¶ Ø§Ù„Ø¹Ø§Ù…
        general_disease_name = map_to_general_diseases(original_name)
        
        if general_disease_name == 'ØºÙŠØ±_Ù…Ø¹Ø±ÙˆÙ':
            continue
            
        if general_disease_name not in class_mapping:
            class_mapping[general_disease_name] = len(class_names)
            class_names.append(general_disease_name)
        
        class_idx = class_mapping[general_disease_name]
        print(f"ðŸŽ¯ Ù…Ø¹Ø§Ù„Ø¬Ø©: {original_name} â†’ {general_disease_name}")
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            image_files.extend(list(Path(class_info['path']).glob(ext)))
        
        image_files = image_files[:max_images_per_class]
        loaded_count = 0
        
        for image_file in image_files:
            try:
                image = simple_preprocess_image(image_file)
                if image is not None:
                    images.append(image)
                    labels.append(class_idx)
                    loaded_count += 1
                    
                    if loaded_count % 100 == 0:
                        print(f"   ðŸ“¸ ØªÙ… ØªØ­Ù…ÙŠÙ„ {loaded_count} ØµÙˆØ±Ø©...")
            except:
                continue
        
        print(f"   âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {loaded_count} ØµÙˆØ±Ø© Ù…Ù† {general_disease_name}")
    
    if not images:
        print("âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ ØµÙˆØ±!")
        return None, None, None
    
    print(f"ðŸŽ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù…ÙŠÙ„: {len(images)} ØµÙˆØ±Ø©ØŒ {len(class_names)} ÙØ¦Ø©")
    print(f"ðŸ“‹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©: {class_names}")
    
    X = np.array(images)
    y = np.array(labels)
    
    return X, y, class_names

def check_class_balance(y, class_names):
    """ÙØ­Øµ ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª"""
    unique, counts = np.unique(y, return_counts=True)
    
    print("ðŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª:")
    for cls, count in zip(unique, counts):
        print(f"   {class_names[cls]}: {count} Ø¹ÙŠÙ†Ø©")
    
    # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙˆØ§Ø²Ù†
    if len(counts) > 0:
        balance_ratio = np.min(counts) / np.max(counts)
        print(f"ðŸ“ˆ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªÙˆØ§Ø²Ù†: {balance_ratio:.3f}")
        
        if balance_ratio < 0.3:
            print("âš ï¸ ØªØ­Ø°ÙŠØ±: Ø§Ù„ÙØ¦Ø§Øª ØºÙŠØ± Ù…ØªÙˆØ§Ø²Ù†Ø© Ø¨Ø´ÙƒÙ„ Ø®Ø·ÙŠØ±!")
            return False, counts
        elif balance_ratio < 0.5:
            print("âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ø§Ù„ÙØ¦Ø§Øª ØºÙŠØ± Ù…ØªÙˆØ§Ø²Ù†Ø© Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯")
            return False, counts
        else:
            print("âœ… Ø§Ù„ÙØ¦Ø§Øª Ù…ØªÙˆØ§Ø²Ù†Ø© Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯")
            return True, counts
    
    return False, counts

def compute_class_weights(y):
    """Ø­Ø³Ø§Ø¨ Ø£ÙˆØ²Ø§Ù† Ø§Ù„ÙØ¦Ø§Øª Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù†"""
    class_weights = compute_class_weight(
        'balanced',
        classes=np.unique(y),
        y=y
    )
    return dict(enumerate(class_weights))

def augment_data(X, y):
    """Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    print("ðŸ”„ Ø¬Ø§Ø±ÙŠ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    from tensorflow.keras.preprocessing.image import ImageDataGenerator
    
    datagen = ImageDataGenerator(
        rotation_range=30,
        width_shift_range=0.3,
        height_shift_range=0.3,
        shear_range=0.3,
        zoom_range=0.3,
        horizontal_flip=True,
        vertical_flip=True,
        brightness_range=[0.8, 1.2],
        fill_mode='nearest'
    )
    
    X_augmented = [img for img in X]
    y_augmented = [label for label in y]
    
    # Ø²ÙŠØ§Ø¯Ø© ÙƒÙ„ ØµÙˆØ±Ø© Ù…Ø±ØªÙŠÙ†
    for i in range(len(X)):
        img = X[i]
        img_expanded = np.expand_dims(img, axis=0)
        
        # ØªØ·Ø¨ÙŠÙ‚ ØªØ­ÙˆÙŠÙ„ÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†
        for j, batch in enumerate(datagen.flow(img_expanded, batch_size=1)):
            X_augmented.append(batch[0])
            y_augmented.append(y[i])
            if j == 1:  # ØµÙˆØ±ØªÙŠÙ† Ø¥Ø¶Ø§ÙÙŠØªÙŠÙ† Ù„ÙƒÙ„ ØµÙˆØ±Ø©
                break
    
    X_augmented = np.array(X_augmented)
    y_augmented = np.array(y_augmented)
    
    print(f"ðŸ“ˆ Ø¨Ø¹Ø¯ Ø§Ù„Ø²ÙŠØ§Ø¯Ø©: {len(X_augmented)} ØµÙˆØ±Ø©")
    
    return X_augmented, y_augmented

def main():
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    os.makedirs('models', exist_ok=True)
    os.makedirs('data/processed', exist_ok=True)
    
    # Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    data_paths = [
        'data/PlantVillage',
        'data/plantvillage', 
        'PlantVillage',
        '../data/PlantVillage'
    ]
    
    data_dir = None
    for path in data_paths:
        if os.path.exists(path):
            data_dir = path
            print(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {data_dir}")
            break
    
    if not data_dir:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª PlantVillage!")
        return
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    print("ðŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¹Ø§Ù…Ø©...")
    X, y, class_names = load_plant_disease_data(data_dir, max_images_per_class=400)
    
    if X is None or len(X) == 0:
        print("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")
        return
    
    print(f"ðŸ“Š Ø´ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {X.shape}")
    print(f"ðŸŽ¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {class_names}")
    
    # ÙØ­Øµ ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª
    is_balanced, class_counts = check_class_balance(y, class_names)
    
    # Ø­Ø³Ø§Ø¨ Ø£ÙˆØ²Ø§Ù† Ø§Ù„ÙØ¦Ø§Øª
    class_weights = compute_class_weights(y)
    print(f"âš–ï¸ Ø£ÙˆØ²Ø§Ù† Ø§Ù„ÙØ¦Ø§Øª: {class_weights}")
    
    # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ù…ÙƒØ«Ù
    print("ðŸ”„ ØªØ·Ø¨ÙŠÙ‚ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙƒØ«ÙØ©...")
    X, y = augment_data(X, y)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ³Ù…ÙŠØ§Øª
    y_categorical = tf.keras.utils.to_categorical(y, num_classes=len(class_names))
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_categorical, 
        test_size=0.15, 
        random_state=42, 
        stratify=y,
        shuffle=True
    )
    
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, 
        test_size=0.15, 
        random_state=42,
        stratify=np.argmax(y_train, axis=1),
        shuffle=True
    )
    
    print(f"ðŸ“ˆ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {X_train.shape[0]} Ø¹ÙŠÙ†Ø©")
    print(f"ðŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚: {X_val.shape[0]} Ø¹ÙŠÙ†Ø©") 
    print(f"ðŸ§ª Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {X_test.shape[0]} Ø¹ÙŠÙ†Ø©")
    
    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    print("ðŸ”„ Ø¬Ø§Ø±ÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
    model_builder = PlantDiseaseModel(
        input_shape=(224, 224, 3), 
        num_classes=len(class_names)
    )
    model = model_builder.build_model()
    
    print("ðŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:")
    model.summary()
    
    # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    print("ðŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
    history = model_builder.train(
        X_train, y_train, 
        X_val, y_val, 
        class_weights=class_weights,
        epochs=50,
        batch_size=32
    )
    
    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    print("ðŸ§ª Ø¬Ø§Ø±ÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...")
    test_loss, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test, verbose=0)
    
    print(f"ðŸŽ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    print(f"   ðŸ“Š Ø§Ù„Ø¯Ù‚Ø©: {test_accuracy:.4f}")
    print(f"   ðŸŽ¯ Ø§Ù„Ø¯Ù‚Ø© (Precision): {test_precision:.4f}")
    print(f"   ðŸ” Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ (Recall): {test_recall:.4f}")
    print(f"   ðŸ“‰ Ø§Ù„Ø®Ø³Ø§Ø±Ø©: {test_loss:.4f}")
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if test_accuracy < 0.6:
        print("âŒ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¶Ø¹ÙŠÙ Ø§Ù„Ø£Ø¯Ø§Ø¡!")
        print("ðŸ’¡ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:")
        print("   - Ø²ÙŠØ§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        print("   - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙƒØ«Ø± ØªÙˆØ§Ø²Ù†Ø§Ù‹")
        print("   - ØªØ¬Ø±Ø¨Ø© Ø¨Ù†ÙŠØ© Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØªÙ„ÙØ©")
    elif test_accuracy < 0.8:
        print("âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡")
    else:
        print("âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù…ØªØ§Ø² Ø§Ù„Ø£Ø¯Ø§Ø¡!")
    
    # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model.save('models/plant_disease_model.keras')
    print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: models/plant_disease_model.keras")
    
    # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙØ¦Ø§Øª
    class_info = {
        'class_names': class_names,
        'class_indices': {name: idx for idx, name in enumerate(class_names)},
        'num_classes': len(class_names),
        'test_accuracy': float(test_accuracy),
        'test_precision': float(test_precision),
        'test_recall': float(test_recall),
        'training_samples': len(X),
        'class_distribution': {class_names[i]: int(count) for i, count in enumerate(class_counts)},
        'timestamp': str(np.datetime64('now'))
    }
    
    with open('models/class_info.json', 'w', encoding='utf-8') as f:
        json.dump(class_info, f, ensure_ascii=False, indent=2)
    
    print("âœ… ØªÙ… Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ: models/class_info.json")
    
    # Ø±Ø³Ù… Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    plot_training_results(history, test_accuracy)
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø©
    test_prediction(model, X_test, y_test, class_names)

def plot_training_results(history, test_accuracy):
    """Ø±Ø³Ù… Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    try:
        plt.figure(figsize=(15, 5))
        
        # Ø§Ù„Ø¯Ù‚Ø©
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'], label='Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨', linewidth=2)
        plt.plot(history.history['val_accuracy'], label='Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚', linewidth=2)
        plt.axhline(y=test_accuracy, color='r', linestyle='--', label=f'Ø¯Ù‚Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {test_accuracy:.3f}')
        plt.title('ØªØ·ÙˆØ± Ø§Ù„Ø¯Ù‚Ø© Ø®Ù„Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨', fontsize=14, fontweight='bold')
        plt.ylabel('Ø§Ù„Ø¯Ù‚Ø©', fontsize=12)
        plt.xlabel('Ø§Ù„Ø¯ÙˆØ±Ø©', fontsize=12)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # Ø§Ù„Ø®Ø³Ø§Ø±Ø©
        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'], label='Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨', linewidth=2)
        plt.plot(history.history['val_loss'], label='Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ­Ù‚Ù‚', linewidth=2)
        plt.title('ØªØ·ÙˆØ± Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø®Ù„Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨', fontsize=14, fontweight='bold')
        plt.ylabel('Ø§Ù„Ø®Ø³Ø§Ø±Ø©', fontsize=12)
        plt.xlabel('Ø§Ù„Ø¯ÙˆØ±Ø©', fontsize=12)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('models/training_results.png', dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
        
        print("ðŸ“Š ØªÙ… Ø­ÙØ¸ Ø±Ø³Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ: models/training_results.png")
        
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø±Ø³Ù… Ø§Ù„Ù†ØªØ§Ø¦Ø¬: {e}")

def test_prediction(model, X_test, y_test, class_names):
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    print("\nðŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©...")
    
    if len(X_test) == 0:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±!")
        return
        
    # Ø§Ø®ØªÙŠØ§Ø± 5 Ø¹ÙŠÙ†Ø§Øª Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
    indices = np.random.choice(len(X_test), min(5, len(X_test)), replace=False)
    
    correct_predictions = 0
    total_predictions = len(indices)
    
    for i, idx in enumerate(indices):
        test_image = X_test[idx]
        true_label = np.argmax(y_test[idx])
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        prediction = model.predict(np.expand_dims(test_image, axis=0), verbose=0)
        predicted_class = np.argmax(prediction[0])
        confidence = np.max(prediction[0])
        
        is_correct = true_label == predicted_class
        if is_correct:
            correct_predictions += 1
        
        print(f"ðŸ“¸ Ø§Ù„Ø¹ÙŠÙ†Ø© {i+1}:")
        print(f"   âœ… Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©: {class_names[true_label]}")
        print(f"   ðŸ¤– Ø§Ù„ØªÙ†Ø¨Ø¤: {class_names[predicted_class]}")
        print(f"   ðŸ“Š Ø§Ù„Ø«Ù‚Ø©: {confidence:.3f}")
        print(f"   {'ðŸŽ‰ ØµØ­ÙŠØ­' if is_correct else 'âŒ Ø®Ø·Ø£'}")
        print()
    
    accuracy = correct_predictions / total_predictions
    print(f"ðŸ“ˆ Ø¯Ù‚Ø© Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©: {accuracy:.2%} ({correct_predictions}/{total_predictions})")

if __name__ == "__main__":
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    tf.keras.backend.clear_session()
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    main()